{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depressinator -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.backend import expand_dims\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path = 'C:/Users/DELL/PycharmProjects/Depression-Detector-by-Nueral-Network/Assignment/data/'\n",
    "\n",
    "condition_dir = os.path.join(data_path, \"condition\")\n",
    "control_dir = os.path.join(data_path, \"control\")\n",
    "scores_file = os.path.join(data_path, \"scores.csv\")\n",
    "\n",
    "conditions = [pd.read_csv(os.path.join(condition_dir, filename)) for filename in os.listdir(condition_dir)]\n",
    "\n",
    "controls = [pd.read_csv(os.path.join(control_dir, filename)) for filename in os.listdir(control_dir)]\n",
    "\n",
    "scores_data = pd.read_csv(scores_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condition Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ymax = 8500\n",
    "\n",
    "# iterate over all files and plot\n",
    "for i in range(23):\n",
    "    j = 1+i\n",
    "    my_file = data_path + 'condition/condition_' + str(j) + '.csv'\n",
    "    df_temp = pd.read_csv(my_file)\n",
    "\n",
    "    # plot full activity time series\n",
    "    my_alpha=0.25\n",
    "    fig, ax = plt.subplots(figsize=(18,6))\n",
    "    ax.scatter(df_temp.timestamp, df_temp.activity , alpha=my_alpha)\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(20)) # reduce number of x-axis labels\n",
    "    ax.set_ylim(0, ymax)\n",
    "    plt.title(my_file)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.grid()\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ymax = 8500\n",
    "\n",
    "# iterate over all files and plot\n",
    "for i in range(23):\n",
    "    j = 1+i\n",
    "    my_file = data_path + 'control/control_' + str(j) + '.csv'\n",
    "    df_temp = pd.read_csv(my_file)\n",
    "\n",
    "    # plot full activity time series\n",
    "    my_alpha=0.25\n",
    "    fig, ax = plt.subplots(figsize=(18,6))\n",
    "    ax.scatter(df_temp.timestamp, df_temp.activity , alpha=my_alpha)\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(20)) # reduce number of x-axis labels\n",
    "    ax.set_ylim(0, ymax)\n",
    "    plt.title(my_file)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.grid()\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scores_data.head()\n",
    "scores_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xs = [\"Condition\", \"Control\"]\n",
    "ys = [len(conditions), len(controls)]\n",
    "\n",
    "print(f\"Condition number: {len(conditions)}\")\n",
    "print(f\"Control number: {len(controls)}\")\n",
    "\n",
    "plt.bar(xs, ys)\n",
    "plt.xlabel(\"Group\")\n",
    "plt.ylabel(\"Patients\")\n",
    "plt.title(\"Number of patients per group\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "condition_rows = pd.Series([len(df) for df in conditions])\n",
    "condition_rows.describe()\n",
    "\n",
    "control_rows = pd.Series([len(df) for df in controls])\n",
    "control_rows.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns and types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conditions[0].dtypes\n",
    "controls[0].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "condition_NaNs = pd.Series([df[\"activity\"].isna().sum() for df in conditions])\n",
    "condition_NaNs.mean()\n",
    "\n",
    "control_NaNs = pd.Series([df[\"activity\"].isna().sum() for df in controls])\n",
    "control_NaNs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(1, 24):\n",
    "\tdf = pd.read_csv(\"data\\condition\\condition_{}.csv\".format(i))\n",
    "\tx1 = np.array(df['activity'].tolist())\n",
    "\tX.append(x1)\n",
    "\ty.append(1)\n",
    "\n",
    "for i in range(1, 33):\n",
    "\tdf = pd.read_csv(\"data\\control\\control_{}.csv\".format(i))\n",
    "\tx1 = np.array(df['activity'].tolist())\n",
    "\tX.append(x1)\n",
    "\ty.append(0)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X = pad_sequences(\n",
    "\tX,\n",
    "\tmaxlen=max([len(x1) for x1 in X]),\n",
    "\tpadding='post',\n",
    "\ttruncating='post',\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "model = models.Sequential([\n",
    "\tlayers.Dense(128, activation='relu', input_shape=X_train.shape[1:]),\n",
    "\tlayers.Dropout(0.3),\n",
    "\n",
    "\tlayers.Dense(64, activation='relu'),\n",
    "\tlayers.Dropout(0.3),\n",
    "\n",
    "\tlayers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "\toptimizer=\"adam\",\n",
    "\tloss=\"binary_crossentropy\",\n",
    "\tmetrics=[\"binary_accuracy\"],\n",
    ")\n",
    "\n",
    "acc = 0\n",
    "while(acc <= 0.80):\n",
    "\thistory = model.fit(\n",
    "\t\tX_train,\n",
    "\t\ty_train,\n",
    "\t\tvalidation_data=(X_test, y_test),\n",
    "\t\tbatch_size=60,\n",
    "\t\tepochs=1,\n",
    "\t)\n",
    "\tacc = history.history['val_binary_accuracy'][-1]\n",
    "\n",
    "model.save(\"depression.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Depression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"depression.h5\")\n",
    "\n",
    "def deep_depression_detector(activity_data_csv_file):\n",
    "\tdf = pd.read_csv(activity_data_csv_file)\n",
    "\tx = np.array([df['activity'].tolist()])\n",
    "\tx = pad_sequences(\n",
    "\t\tx, maxlen=65407,\n",
    "\t\tpadding='post',\n",
    "\t\ttruncating='post'\n",
    "\t)\n",
    "\n",
    "\ty_pred = model.predict(x)\n",
    "\tif y_pred >= 0.5:\n",
    "\t\treturn  {'prediction':'depressed'}\n",
    "\telse:\n",
    "\t\treturn  {'prediction':'nondepressed'}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}